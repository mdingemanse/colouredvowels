---
title: "Coloured vowels: open data and code"
output:
  github_document: default
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
    theme: united
---
```{r global_options, include=FALSE}
#run the outcommented render command below to generate both .html and .md output, the latter of which will be rendered nicely on GitHub:
#rmarkdown::render("BRM_colouredvowels_opendata.Rmd", output_format = "all",encoding="UTF-8")
knitr::opts_chunk$set(fig.path='figs/', echo=TRUE, warning=FALSE, message=FALSE)

```

```{r preliminaries, results='hide',include=F}

rm(list=ls())

# Packages and useful functions
list.of.packages <- c("tidyverse")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)>0) install.packages(new.packages)
lapply(list.of.packages, require, character.only=T)
rm(list.of.packages,new.packages)

`%notin%` <- function(x,y) !(x %in% y) 

load("BRM_colouredvowels_opendata.Rdata")

```

## Intro
This dataset and code accompanies the following paper on categorical perception and structure in vowel-colour mappings:

> Cuskley, C.<sup>1</sup>, Dingemanse, M.<sup>1</sup>, van Leeuwen, T. & Kirby, S. 2019. Cross-modal associations and synaesthesia: Categorical perception and structure in vowel-colour mappings in a large online sample. *Behaviour Research Methods*, doi: [10.3758/s13428-019-01203-7](https://doi.org/10.3758/s13428-019-01203-7).

<sup>1</sup> Joint first authors & corresponding authors: ccuskley@gmail.com, m.dingemanse@let.ru.nl.

## Data
The data was collected as part of a large-scale study into synaesthesia and cross-modal associations (*Groot Nationaal Onderzoek*, Van Leeuwen & Dingemanse 2016). Spoken vowel-colour association data was collected for **`r length(d.participants$anonid)` participants** using recordings of 16 vowel sounds selected to represent points spread through acoustic vowel space (Moos et al. 2014). Grapheme-colour association data was collected for a subset of 398 participants who took a full grapheme-colour association test, among them are around 100 confirmed synaesthetes.

The focus of this paper is on colour associations to spoken vowel sounds. Data comes in the following data frames (shared in .csv and .Rdata formats): `d.voweldata` for the raw data from the association task (with `d.stimuli` recording order of presentation) and `d.participants` for anonymised participant metadata and consistency and structure scores.

* [BRM_colouredvowels_voweldata.csv](/BRM_colouredvowels_voweldata.csv)
* [BRM_colouredvowels_stimuli.csv](/BRM_colouredvowels_stimuli.csv)
* [BRM_colouredvowels_participants.csv](/BRM_colouredvowels_participants.csv)

The raw data from the association task looks like this:

```{r data}
str(d.voweldata)

```
Here, `anonid` is an anonymised participant identifier; `setname` records the item randomisation a participant was exposed to (as specified in `d.stimuli`); `item` lists item as presented in the test; and `color` and `timing` record colour choice and RT per trial (each item is presented three times).

Participant metadata is in `d.participants` and looks like this:
```{r data-structure-profile}
str(d.participants)
```

The `anonid` allows linking across test results and metadata. Age, binarised gender and self-reported synaesthesia were recorded using an optional pre-test questionnaire, which about 75% of participants filled out. Age (`age_bin`) is binned to ensure participant privacy; reported age range is 18-88 (median = 46, SD = 16).  Participants identifying as female are overrepresented, which is common in self-selecting online studies. In the paper, we don't use self-reported synaesthesia in the analyses as we don't know what types of synaesthesia people may have; instead, we compute synaesthesia based on the consistency of people's responses across three trials in grapheme-colour and vowel-colour tasks (`syn_status`), as customary in synaesthesia research.

`consistency` is an overall measure of consistency in colour choices, based on distances in CIELuv space (lower = more consistent). 34 out of 1164 participants received no consistency score as they chose "No colour" for more than half of the items. `syn_status` is a synaesthesia classification based on the consistency score, as reported in the paper; we identified 365 synaesthetes. Finally, `r`, `structure` (also called *z score* in the paper), and `p-value` are related to the novel Structure measure we introduce in the paper, which characterizes the degree to which participants' responses are structured isomorphically across modalities (higher = more isomorphic).

## Code
Part of our analysis is in Python. [BRM_colouredvowels_MantelCode.py](/BRM_colouredvowels_MantelCode.py) has the code for computing structure scores using the Mantel test.

Also, if you're interested in the code for the online cross-modal association test, have a look at [SenseTest](/SenseTest).

## Examples

What does it look like when you ask people to associate colours to vowel sounds? Here are some samples from the data (more details in the paper). 

These panels plot vowel-colour associations in vowel space, with *i* top left, *u* top right, and *a* bottom center. Each triangle represents the data for one participant. The small circles represent individual trials (randomly presented in the experiment), and each little row of three trials represents a single vowel sound (16 in total). 

The first panel shows 12 participants who score inside the range usually considered synaesthetic. These participants succeed in picking very similar colours each time they hear the same sound, reflected in consistency scores below 135 (the lower this score, the lower the colour distance within trials). Groupings can be easily discerned — for instance, many people group the first 2 or 3 items on the top left, representing *i* sounds. And most seem to pick lighter colours for [i] than for [a], while the darkest colours tend to be reserved for [u].


```{r examples, echo=FALSE, warning=FALSE, message=FALSE}
source(file="BRM_colouredvowels_functions.R")

# 12 relatively structured participants scoring in the synaesthete range
vowelspaces(n=12,max.consistency=135,min.structure=3.7,sort=T,printpid=F)
```

The second panel shows the responses of 12 participants who score outside the synaesthetic range. There is quite a bit of irregularity: these participants seldom make exactly the same choice for a given item across trials, reflected in consistency scores of 135 and up (the higher, the more dissimilar the colours chosen across trials for an item). But like with the synaesthetes, some patterns do appear: the left side (with vowels like [i, e]) generally gets lighter, greener colours while the right side (with vowels like [u, ɔ] generally gets darker, bluer colours.

```{r examples2, echo=FALSE, warning=FALSE, message=FALSE}
# 12 relatively structured participants scoring outside the synaesthetic range
vowelspaces(n=12,min.consistency=135,min.structure=3.7,sort=T,printpid=F)
```

### More data
While the above plots are fairly representative, they still divide the data into non-synaesthetes and synaesthetes, which may or may not make sense depending on your taste or theoretical commitments. Using `vowelspaces()`, we can easily plot larger arrays from the raw data and sort by consistency score to see the increasing entropy of choices. Since these are semi-randomly drawn from the full dataset, expect to see weird patterns or NA responses sometimes as well. Here are three successive sets of 12 participants roughly representing three tertiles of consistency scores (<135, 135-210, >210):

```{r examples3,echo=FALSE, warning=FALSE,message=FALSE}
vowelspaces(sort=T,min.consistency=30,max.consistency=135,n=12,printpid=F)
vowelspaces(sort=T,min.consistency=135,max.consistency=210,n=12,printpid=F)
vowelspaces(sort=T,min.consistency=210,max.consistency=350,n=12,printpid=F)

```

A key metric we introduce in the paper is Structure, which measures the degree to which domains are mapped isomorphically. One finding of our study is that the associations of over two thirds of people show a significant degree of structure. These structured solutions to mapping the vowel and colour spaces are surprisingly similar across participants, as can be seen especially clearly for participants in the upper quartile of the structure scores:

```{r examples4,echo=FALSE, warning=FALSE, message=FALSE}
# high structure is beautiful regardless of consistency
vowelspaces(min.structure=6.1,n=16,printpid=F,sort=T)
```